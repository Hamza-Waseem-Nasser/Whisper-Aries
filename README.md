# Whisper Large-v3 Transcription System

A production-ready Arabic/English transcription system using OpenAI's Whisper Large-v3 with GPU acceleration and INT8 quantization.

## üéØ Features

- **Whisper Large-v3** with INT8 quantization for speed
- **GPU acceleration** (CUDA) with CPU fallback
- **Arabic & English** optimized transcription
- **Multiple output formats**: JSON, TXT, SRT subtitles
- **Batch processing** for multiple files
- **Word-level timestamps** for precise alignment
- **Voice Activity Detection** (VAD) support

## üîß Quick Setup

### 1. Clone and Setup Environment

```bash
git clone <your-repo-url>
cd whisper-project
python -m venv whisper-env
```

**Windows:**
```powershell
.\whisper-env\Scripts\Activate.ps1
```

**Linux/Mac:**
```bash
source whisper-env/bin/activate
```

### 2. Install Dependencies

**Option A: Automated Installation (Recommended)**
```bash
python install_packages.py
```

**Option B: Manual Installation**
```bash
pip install --upgrade pip
# IMPORTANT: Install PyTorch with CUDA 12.1 support FIRST
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
# Then install other packages
pip install faster-whisper
pip install onnxruntime-gpu
pip install librosa soundfile scipy av
pip install huggingface-hub tokenizers tqdm numba matplotlib
```

**Option C: Requirements File (may have dependency conflicts)**
```bash
pip install -r requirements.txt
```

‚ö†Ô∏è **IMPORTANT**: Package installation order matters! Use Option A for best results.

### 3. Verify Installation

```bash
python verify_setup.py
```

## üöÄ Quick Start

### Single File Transcription

```bash
# Basic usage
python transcribe.py audio_file.mp3

# With specific output format
python transcribe.py audio_file.mp3 --format json    # Detailed JSON
python transcribe.py audio_file.mp3 --format txt     # Plain text
python transcribe.py audio_file.mp3 --format srt     # Subtitles
```

### Batch Processing

```bash
# Process all audio files in current directory
python batch_transcribe.py

# Process specific directory
python batch_transcribe.py --input-dir "path/to/audio" --output-dir "path/to/results"
```

### Demo Script

```bash
# Auto-detect and transcribe audio files
python demo.py
```

## üìÅ Project Structure

```
whisper-project/
‚îú‚îÄ‚îÄ README.md                    # This file
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ config.py                    # Configuration settings
‚îú‚îÄ‚îÄ transcribe.py               # Main transcription script
‚îú‚îÄ‚îÄ batch_transcribe.py         # Batch processing
‚îú‚îÄ‚îÄ demo.py                     # Simple demo
‚îú‚îÄ‚îÄ verify_setup.py             # Installation verification
‚îú‚îÄ‚îÄ examples/                   # Example audio files
‚îÇ   ‚îî‚îÄ‚îÄ sample_audio.wav
‚îú‚îÄ‚îÄ docs/                       # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ setup_guide.md
‚îÇ   ‚îú‚îÄ‚îÄ troubleshooting.md
‚îÇ   ‚îî‚îÄ‚îÄ api_reference.md
‚îî‚îÄ‚îÄ scripts/                    # Utility scripts
    ‚îú‚îÄ‚îÄ setup_environment.py
    ‚îî‚îÄ‚îÄ benchmark.py
```

## ‚ö° Performance

- **GPU Mode**: ~5-10x faster than real-time
- **CPU Mode**: ~2-3x faster than real-time  
- **Memory Usage**: ~3-4GB VRAM (GPU) or ~4-6GB RAM (CPU)
- **Model Size**: ~3GB download (first run only)

## üåç Language Support

- **Arabic**: Excellent accuracy with proper UTF-8 encoding
- **English**: Native support with high accuracy
- **Auto-detection**: Automatic language identification
- **Mixed content**: Handles Arabic-English mixed audio

## üìä Output Formats

### JSON (Detailed)
```json
{
  "language": "ar",
  "confidence": 0.99,
  "segments": [
    {
      "start": 0.0,
      "end": 3.5,
      "text": "ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ŸÉŸÖ",
      "words": [...]
    }
  ]
}
```

### TXT (Plain Text)
```
ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ŸÉŸÖ ŸÅŸä Ÿáÿ∞ÿß ÿßŸÑÿ®ÿ±ŸÜÿßŸÖÿ¨
Welcome to this program
```

### SRT (Subtitles)
```
1
00:00:00,000 --> 00:00:03,500
ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ŸÉŸÖ ŸÅŸä Ÿáÿ∞ÿß ÿßŸÑÿ®ÿ±ŸÜÿßŸÖÿ¨

2
00:00:03,500 --> 00:00:07,000
Welcome to this program
```

## üîß Configuration

Edit `config.py` to customize:

```python
# Model settings
MODEL_SIZE = "large-v3"      # large-v3, medium, small
DEVICE = "auto"              # auto, cuda, cpu
COMPUTE_TYPE = "int8"        # int8, float16, float32

# Languages
LANGUAGES = ["ar", "en"]     # Arabic, English
AUTO_DETECT = True

# Performance
VAD_FILTER = True           # Voice Activity Detection
BEAM_SIZE = 5               # Search beam size
TEMPERATURE = 0.0           # Sampling temperature
```

## üõ†Ô∏è Troubleshooting

### GPU Issues
```bash
# Check GPU status
nvidia-smi

# Test CUDA availability
python -c "import torch; print(torch.cuda.is_available())"
```

### Memory Issues
- Switch to CPU mode: Set `DEVICE = "cpu"` in config.py
- Use smaller model: Set `MODEL_SIZE = "medium"`
- Reduce batch size for multiple files

### Audio Format Issues
- Supported: MP3, WAV, M4A, FLAC, OGG, MP4, WEBM
- Convert unsupported formats to WAV/MP3 first

## üìà System Requirements

### Minimum
- **OS**: Windows 10+, Linux, macOS
- **Python**: 3.10 or 3.11
- **RAM**: 8GB
- **Storage**: 10GB free space

### Recommended (GPU)
- **GPU**: NVIDIA RTX 3050+ with 4GB+ VRAM
- **CUDA**: 11.8+ or 12.x
- **RAM**: 16GB
- **Storage**: SSD with 20GB+ free space

## üîÑ Updates

```bash
# Update packages
pip install --upgrade faster-whisper torch torchaudio

# Update repository
git pull origin main
```

## üìû Support

- Check `docs/troubleshooting.md` for common issues
- Run `python verify_setup.py` to diagnose problems
- Create GitHub issues for bugs or feature requests

## üìÑ License

MIT License - see LICENSE file for details

---

**Ready to transcribe!** üé§ ‚û°Ô∏è üìù
